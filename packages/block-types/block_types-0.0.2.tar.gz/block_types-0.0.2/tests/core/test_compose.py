# AUTOGENERATED! DO NOT EDIT! File to edit: nbs/00_tests/core/compose.ipynb (unless otherwise specified).

__all__ = ['column_transformer_data_fixture', 'multi_split_data_fixture', 'test_multi_comp_io', 'test_multi_comp_desc',
           'test_athena_pipeline_training', 'test_multi_comp_hierarchy', 'test_multi_comp_profiling',
           'test_multi_comp_all_equal', 'Transform1', 'Transform2', 'test_pipeline_fit_apply',
           'test_pipeline_fit_apply_bis', 'test_pipeline_new_comp', 'test_pipeline_set_comp',
           'test_athena_pipeline_training', 'test_pipeline_load_estimator', 'test_make_pipeline',
           'test_column_selector', 'column_transformer_data', 'test_make_column_transformer',
           'test_make_column_transformer_passthrough', 'test_make_column_transformer_remainder',
           'test_make_column_transformer_descendants', 'test_make_column_transformer_fit_transform', 'Transform1',
           'Transform2', 'multi_split_data', 'test_multi_split_transform', 'test_multi_split_fit',
           'test_multi_split_chain', 'test_multi_split_io', 'test_multi_split_non_dict',
           'test_multi_split_non_dict_bis']

# Cell
import pytest
import os
import joblib
from IPython.display import display
import pandas as pd
import numpy as np
import time

from sklearn.preprocessing import StandardScaler
from sklearn.utils import Bunch
from sklearn.preprocessing import FunctionTransformer

from block_types.core.compose import *
from block_types.core.block_types import (Component,
                                          PandasComponent)
from block_types.core.utils import PickleIO
from block_types.utils.utils import remove_previous_results
from block_types.core.block_types import Component, PickleSaverComponent

import block_types.config.bt_defaults as dflt

# Cell
@pytest.fixture (name='column_transformer_data')
def column_transformer_data_fixture():
    return column_transformer_data()

@pytest.fixture (name='multi_split_data')
def multi_split_data_fixture():
    return multi_split_data()

# Comes from compose.ipynb, cell
#@pytest.mark.reference_fails
def test_multi_comp_io ():

    path_results = 'multi_component_loading_saving'
    remove_previous_results (path_results=path_results)

    # 1. by setting components as attributes:
    class NewComposition(MultiComponent):

        def __init__ (self, **kwargs):
            data_io = PickleIO (**kwargs)
            super().__init__(data_io=data_io,
                             **kwargs)

            self.tr1 = Component(FunctionTransformer (lambda x: x*3),
                                 data_io=data_io,
                                 name='tr1')
            self.tr2 = Component(FunctionTransformer (lambda x: x*2),
                                 data_io=data_io,
                                 name='tr2')

        def _apply (self, X):
            return self.tr1 (X) + self.tr2(X)

    X = np.array([1,2,3])

    composition1 = NewComposition (path_results=path_results)
    result1 = composition1 (X)

    composition2 = NewComposition (path_results=path_results)
    result2 = composition2.data_io.load_result()
    assert (result1==result2).all()

    resut_tr1_2 = composition2.tr1.data_io.load_result()
    resut_tr2_2 = composition2.tr2.data_io.load_result()
    assert (resut_tr1_2==composition1.tr1(X)).all()
    assert (resut_tr2_2==composition1.tr2(X)).all()

    assert sorted(os.listdir (f'{path_results}/whole'))==['new_composition_result.pk', 'tr1_result.pk', 'tr2_result.pk']

    composition1.set_split ('validation')
    result1b = composition1 (X)
    assert sorted(os.listdir (f'{path_results}/validation'))==['new_composition_result.pk', 'tr1_result.pk', 'tr2_result.pk']

    remove_previous_results (path_results=f'{path_results}/whole')

    resut_tr1_2 = composition2.tr1.data_io.load_result(split='validation')
    resut_tr2_2 = composition2.tr2.data_io.load_result()

    assert (resut_tr1_2==composition1.tr1(X)).all()
    assert resut_tr2_2 is None

    composition2.set_split('validation')
    resut_tr1_2 = composition2.tr1.data_io.load_result()
    resut_tr2_2 = composition2.tr2.data_io.load_result()

    assert (resut_tr1_2==composition1.tr1(X)).all()
    assert (resut_tr2_2==composition1.tr2(X)).all()

    remove_previous_results (path_results=path_results)

# Comes from compose.ipynb, cell
#@pytest.mark.reference_fails
def test_multi_comp_desc ():
    class Intermediate (MultiComponent):
        def __init__ (self, name=None, **kwargs):
            super().__init__ (name=name, **kwargs)
            self.first = Component (name='first_component', **kwargs)
            self.second = Component (name='second_component', **kwargs)

    class Higher (MultiComponent):
        def __init__ (self, **kwargs):
            super().__init__ (**kwargs)
            self.first = Intermediate (name='first_intermediate', **kwargs)
            self.second = Intermediate (name='second_intermediate', **kwargs)
            self.gather_descendants(nick_name=False)

    higher = Higher()

    assert sorted(higher.obj.keys())==['first_component', 'first_intermediate', 'second_component', 'second_intermediate']

    # check types
    types = map(lambda x: type(x[1]), sorted(higher.obj.items()))
    assert list(types)==[list, Intermediate, list, Intermediate]

    sorted_list = list(sorted(higher.obj.items()))
    types = map(type, sorted_list[0][1])
    assert list(types)==[Component,Component]

    sorted_list = list(sorted(higher.obj.items()))
    types = map(type, sorted_list[2][1])
    assert list(types)==[Component,Component]

    sorted_keys=list(sorted(higher.cls.keys()))
    assert sorted_keys == ['Component', 'Intermediate']

    assert list(map(type,higher.cls[sorted_keys[0]]))==[Component, Component, Component, Component]

    assert list(map(type,higher.cls[sorted_keys[1]]))==[Intermediate, Intermediate]


    # ***********************
    # recursive behaviour: higher.first
    intermediate = higher.first
    assert sorted(intermediate.obj.keys())==['first_component', 'second_component']

    # check types
    types = map(lambda x: type(x[1]), sorted(intermediate.obj.items()))
    assert list(types)==[Component, Component]

    sorted_keys=list(sorted(intermediate.cls.keys()))
    assert sorted_keys==['Component']

    assert list(map(type,intermediate.cls[sorted_keys[0]]))==[Component,Component]

    # **********************************************
    # recursive behaviour: higher.second
    # **********************************************
    intermediate = higher.second
    assert sorted(intermediate.obj.keys())==['first_component', 'second_component']

    # check types
    types = map(lambda x: type(x[1]), sorted(intermediate.obj.items()))
    assert list(types)==[Component, Component]

    sorted_keys=list(sorted(intermediate.cls.keys()))
    assert sorted_keys==['Component']

    assert list(map(type,intermediate.cls[sorted_keys[0]]))==[Component,Component]

    # **********************************************
    # full hierarchical paths
    # **********************************************
    assert list(sorted(higher.full_cls.keys()))==['Component', 'Intermediate']
    assert higher.full_cls['Intermediate']==['higher.first_intermediate', 'higher.second_intermediate']
    assert higher.full_cls['Component']==['higher.first_intermediate.first_component',
      'higher.first_intermediate.second_component',
      'higher.second_intermediate.first_component',
      'higher.second_intermediate.second_component']

    assert higher.first.full_cls['Component']==['higher.first_intermediate.first_component',
      'higher.first_intermediate.second_component']

    assert list(sorted(higher.full_obj))==['first_component', 'first_intermediate', 'second_component', 'second_intermediate']

    assert higher.full_obj['first_intermediate']=='higher.first_intermediate'

    assert higher.full_obj['first_component']==['higher.first_intermediate.first_component',
      'higher.second_intermediate.first_component']

    assert higher.full_obj['second_component']==['higher.first_intermediate.second_component',
      'higher.second_intermediate.second_component']

    assert higher.full_obj['second_intermediate']=='higher.second_intermediate'

    assert list(sorted(higher.second.full_obj))==['first_component', 'second_component']

    assert higher.second.full_obj['first_component']=='higher.second_intermediate.first_component'

    assert higher.second.full_obj['second_component']=='higher.second_intermediate.second_component'

    assert higher.hierarchy_path=='higher'

    assert higher.first.hierarchy_path=='higher.first_intermediate'

    # with nick_names
    higher.clear_descendants()
    higher.gather_descendants(nick_name=True)

    assert higher.full_cls['Component']==['higher.first.first',
     'higher.first.second',
     'higher.second.first',
     'higher.second.second']

    assert higher.full_obj['first_intermediate']=='higher.first'
    assert higher.full_obj['first_component']==['higher.first.first', 'higher.second.first']
    assert higher.full_obj['second_component']==['higher.first.second', 'higher.second.second']
    assert higher.full_obj['second_intermediate']=='higher.second'

    #Check that we always have attributes for each component name
    assert higher.first_intermediate is higher.first
    assert higher.second_intermediate is higher.second
    assert higher.components==[higher.first, higher.second]

    #check that set_components and add_component create self attrs called
    # the same as the component

    class Higher (MultiComponent):
        def __init__ (self, **kwargs):
            super().__init__ (**kwargs)
            self.set_components (Intermediate (name='first_intermediate', **kwargs),
                                 Intermediate (name='second_intermediate', **kwargs))
    higher = Higher()

    assert higher.components == (higher.first_intermediate, higher.second_intermediate)

    class Higher (MultiComponent):
        def __init__ (self, **kwargs):
            super().__init__ (**kwargs)
            self.add_component (Intermediate (name='first_intermediate', **kwargs))
            self.add_component (Intermediate (name='second_intermediate', **kwargs))
    higher = Higher()

    assert higher.components == [higher.first_intermediate, higher.second_intermediate]

# Comes from compose.ipynb, cell
# second example
# **********************************************
# exports tests.core.test_compose
#@pytest.mark.reference_fails
def test_athena_pipeline_training ():
    class Intermediate (MultiComponent):
        def __init__ (self, name=None, **kwargs):
            super().__init__ (name=name, **kwargs)
            self.first = Component (name=f'{name}_first_component', **kwargs)
            self.second = Component (name=f'{name}_second_component', **kwargs)

    class Higher (MultiComponent):
        def __init__ (self, **kwargs):
            super().__init__ (**kwargs)
            self.first = Intermediate (name='first_intermediate', **kwargs)
            self.second = Intermediate (name='second_intermediate', **kwargs)
            self.gather_descendants(nick_name=False)

    higher = Higher()

    assert sorted(higher.obj.keys())==['first_intermediate', 'first_intermediate_first_component', 'first_intermediate_second_component', 'second_intermediate', 'second_intermediate_first_component', 'second_intermediate_second_component']

    # check types
    types = map(lambda x: type(x[1]), sorted(higher.obj.items()))

    assert list(types)==[Intermediate, Component, Component, Intermediate, Component, Component]

    sorted_keys=list(sorted(higher.cls.keys()))
    assert sorted_keys == ['Component', 'Intermediate']

    assert list(map(type,higher.cls[sorted_keys[0]]))==[Component, Component, Component, Component]
    assert list(map(type,higher.cls[sorted_keys[1]]))==[Intermediate, Intermediate]

    # ***********************
    # recursive behaviour: higher.first
    intermediate = higher.first
    assert sorted(intermediate.obj.keys())==['first_intermediate_first_component', 'first_intermediate_second_component']

    # check types
    types = map(lambda x: type(x[1]), sorted(intermediate.obj.items()))
    assert list(types)==[Component, Component]

    sorted_keys=list(sorted(intermediate.cls.keys()))
    assert sorted_keys==['Component']

    assert list(map(type,intermediate.cls[sorted_keys[0]]))==[Component,Component]

    # ***********************
    # recursive behaviour: higher.second
    intermediate = higher.second
    assert sorted(intermediate.obj.keys())==['second_intermediate_first_component', 'second_intermediate_second_component']

    # check types
    types = map(lambda x: type(x[1]), sorted(intermediate.obj.items()))
    assert list(types)==[Component, Component]

    sorted_keys=list(sorted(intermediate.cls.keys()))
    assert sorted_keys==['Component']

    assert list(map(type,intermediate.cls[sorted_keys[0]]))==[Component,Component]


    # **********************************************
    # full hierarchical paths
    # **********************************************
    assert list(sorted(higher.full_cls))==['Component', 'Intermediate']

    assert higher.full_cls['Component']==['higher.first_intermediate.first_intermediate_first_component',
      'higher.first_intermediate.first_intermediate_second_component',
      'higher.second_intermediate.second_intermediate_first_component',
      'higher.second_intermediate.second_intermediate_second_component']

    assert higher.full_cls['Intermediate']==['higher.first_intermediate', 'higher.second_intermediate']

    assert list(higher.first.full_cls)==['Component']

    assert higher.first.full_cls['Component']==['higher.first_intermediate.first_intermediate_first_component',
      'higher.first_intermediate.first_intermediate_second_component']

    assert sorted(list(higher.full_obj))==['first_intermediate',
     'first_intermediate_first_component',
     'first_intermediate_second_component',
     'second_intermediate',
     'second_intermediate_first_component',
     'second_intermediate_second_component']

    assert higher.full_obj['first_intermediate']=='higher.first_intermediate'

    assert higher.full_obj['first_intermediate_first_component']=='higher.first_intermediate.first_intermediate_first_component'

    assert higher.full_obj['first_intermediate_second_component']=='higher.first_intermediate.first_intermediate_second_component'

    assert higher.full_obj['second_intermediate']=='higher.second_intermediate'

    assert higher.full_obj['second_intermediate_first_component']=='higher.second_intermediate.second_intermediate_first_component'

    assert higher.full_obj['second_intermediate_second_component']=='higher.second_intermediate.second_intermediate_second_component'

    assert list(sorted(higher.second.full_obj))==['second_intermediate_first_component', 'second_intermediate_second_component']

    assert higher.second.full_obj['second_intermediate_first_component']=='higher.second_intermediate.second_intermediate_first_component'

    assert higher.second.full_obj['second_intermediate_second_component']=='higher.second_intermediate.second_intermediate_second_component'

    assert higher.hierarchy_path=='higher'

    assert higher.first.hierarchy_path=='higher.first_intermediate'

# Comes from compose.ipynb, cell
#@pytest.mark.reference_fails
def test_multi_comp_hierarchy ():
    class Intermediate (MultiComponent):
        def __init__ (self, name=None, z=6, h=10, x=3, **kwargs):
            super().__init__ (name=name, **kwargs)
            self.first = Component (name='first_component', **kwargs)
            self.second = Component (name='second_component', **kwargs)

    class Higher (MultiComponent):
        def __init__ (self, x=2, y=3, **kwargs):
            super().__init__ (**kwargs)
            self.first = Intermediate (name='first_intermediate', **kwargs)
            self.second = Intermediate (name='second_intermediate', **kwargs)
            self.gather_descendants()

    higher = Higher()

    levels=dict(
        until=1,
        verbose=1
    )
    higher = Higher (levels=levels, verbose=0)

    assert higher.hierarchy_level==0 and higher.first.hierarchy_level==1 and higher.first.first.hierarchy_level==2

    assert higher.verbose==1 and higher.first.verbose==1 and higher.first.first.verbose==0

    levels['until']=0
    higher = Higher (levels=levels, verbose=0)
    assert higher.verbose==1 and higher.first.verbose==0 and higher.first.first.verbose==0

    levels['until']=2
    higher = Higher (levels=levels, verbose=0)
    assert higher.verbose==1 and higher.first.verbose==1 and higher.first.first.verbose==1

# Comes from compose.ipynb, cell
#@pytest.mark.reference_fails
def test_multi_comp_profiling ():
    class A(Component):
        def __init__ (self, time=1, **kwargs):
            super().__init__(**kwargs)

        def _fit (self, X, y=None):
            time.sleep(self.time*2)

        def _apply (self, X):
            time.sleep(self.time)
            return 1

    class Intermediate (MultiComponent):
        def __init__ (self, name=None, **kwargs):
            super().__init__ (name=name, **kwargs)
            self.first = A (name=f'{name}_first_component', time=0.01, **kwargs)
            self.second = A (name=f'{name}_second_component', time=0.03, **kwargs)
        def _fit (self, X, y=None):
            self.first.fit (X,y)
            self.second.fit (X,y)
        def _apply (self, X):
            _ = self.first.apply (X)
            _ = self.second.apply (X)
            return 1

    class Higher (MultiComponent):
        def __init__ (self, **kwargs):
            super().__init__ (**kwargs)
            self.first = Intermediate (name='first', **kwargs)
            self.second = Intermediate (name='second', **kwargs)
        def _fit (self, X, y=None):
            self.first.fit (X,y)
            self.second.fit (X,y)
        def _apply (self, X):
            _ = self.first.apply (X)
            _ = self.second.apply (X)
            return 1

    higher = Higher()
    higher.fit (1)
    _ = higher.apply (1)
    dfd = higher.gather_times()

    values = dfd.avg[('whole','apply')].values
    assert np.abs(values[1:3].sum() - values[0]) < 0.05
    assert np.abs(values[3:5].sum() - values[1]) < 0.05
    assert np.abs(values[5:7].sum() - values[2]) < 0.05

    values = dfd.avg[('whole','fit')].values
    assert np.abs(values[1:3].sum() - values[0]) < 0.05
    assert np.abs(values[3:5].sum() - values[1]) < 0.05
    assert np.abs(values[5:7].sum() - values[2]) < 0.05

    display('avg', dfd.avg)

    assert (dfd.novh_avg <= dfd.avg).all().all()
    assert (dfd.novh_avg < dfd.avg).any().any()

    assert ((dfd.novh_avg.iloc[-4:].sum(axis=0).to_frame().T) == dfd.no_overhead_total).all(axis=1).all()

    assert ((dfd.avg.iloc[0]-dfd.novh_avg.iloc[-4:].sum(axis=0)).values == dfd.overhead_total.values).all()

    display('no_overhead_total', dfd.no_overhead_total)
    display('overhead_total', dfd.overhead_total)

# Comes from compose.ipynb, cell
#@pytest.mark.reference_fails
def test_multi_comp_all_equal ():
    path_results = 'multi_component_assert_equal'
    remove_previous_results (path_results=path_results)

    # 1. by setting components as attributes:
    class NewComposition(MultiComponent):

        def __init__ (self, noise = 0, **kwargs):
            super().__init__(**kwargs)

            self.tr1 = Component(FunctionTransformer (lambda x: x*3 + noise),
                                 name='tr1',
                                 **kwargs)
            self.tr2 = Component(FunctionTransformer (lambda x: x*2),
                                 name='tr2',
                                 **kwargs)

        def _apply (self, X):
            return self.tr1 (X) + self.tr2(X)

    X = np.array([1,2,3])

    composition1 = NewComposition (path_results=path_results)
    result1 = composition1 (X)

    path_results2 = 'multi_component_assert_equal_2'
    remove_previous_results (path_results=path_results2)
    composition2 = NewComposition (path_results=path_results2)
    result2 = composition2 (X)
    assert composition1.assert_all_equal (path_results2)

    remove_previous_results (path_results=path_results2)
    composition2 = NewComposition (path_results=path_results2, noise=0.1)
    result2 = composition2 (X)
    assert not composition1.assert_all_equal (path_results2)

    # *************************
    # check verbosity
    # *************************
    composition1 = NewComposition (path_results=path_results, verbose=1)
    composition1.logger.info ('\n******************************')
    composition1.logger.info ('verbose')
    composition1.logger.info ('******************************')
    assert not composition1.assert_all_equal (path_results2)

    composition1.logger.info ('\n******************************')
    composition1.logger.info ('not verbose')
    composition1.logger.info ('******************************')
    assert not composition1.assert_all_equal (path_results2, verbose=0)
    composition1.logger.info ('logger works again')

    # *************************
    # remove results
    # *************************
    remove_previous_results (path_results=path_results)
    remove_previous_results (path_results=path_results2)

# Comes from compose.ipynb, cell
# Transform1: custom Transform
class Transform1 (Component):

    def __init__ (self, **kwargs):
        super().__init__ (**kwargs)
        self.estimator= Bunch(sum = 1)

    def _fit (self, X, y=None):
        self.estimator.sum = X.sum(axis=0)

    def _apply (self, x):
        return x*1000 + self.estimator.sum

class Transform2 (Component):

    def __init__ (self, **kwargs):
        super().__init__ (**kwargs)
        self.estimator= Bunch(maxim = 1)

    def _fit (self, X, y=None):
        self.estimator.maxim = X.max(axis=0)

    def _apply (self, x):
        return x*100 + self.estimator.maxim
#@pytest.mark.reference_fails
def test_pipeline_fit_apply ():
    # test `fit_apply` method

    class NewPipeline (Pipeline):

        def __init__ (self, **kwargs):
            super().__init__ (**kwargs)

            # custom transform
            self.tr1 = Transform1(**kwargs)

            # slklearn transform
            self.tr2 = Transform2(**kwargs)

    pipeline = NewPipeline()
    x = np.array([3,4,5])
    r1 = pipeline.fit_apply (x.reshape(-1,1))
    print (r1)

    x1 = x * 1000 + sum(x)
    x2 = x1 * 100 + max(x1)
    assert (r1.ravel()==x2).all()

# Comes from compose.ipynb, cell
#@pytest.mark.reference_fails
def test_pipeline_fit_apply_bis ():
    # test `fit_apply` method
    class NewMulti (MultiComponent):

        def __init__ (self, **kwargs):
            super().__init__ (**kwargs)

            # custom transform
            self.tr1 = Transform1(**kwargs)

            # slklearn transform
            self.tr2 = Transform2(**kwargs)

        def _fit (self, X, y=None):
            self.tr1.fit (X)
            self.tr2.fit (X)

        def _apply (self, X, y=None):
            X1=self.tr1.apply (X)
            X2=self.tr2.apply (X)
            return X1+X2

    new_multi = NewMulti()
    x = np.array([3,4,5])
    r2 = new_multi.fit_apply (x)
    print (r2)

    x2b = 100 * x + max(x)
    x1 = x * 1000 + sum(x)
    assert (r2.ravel()==(x1 + x2b)).all()

# Comes from compose.ipynb, cell
#@pytest.mark.reference_fails
def test_pipeline_new_comp ():
    # test automatic creation of pipeline components

    # 1. by setting components as attributes:
    class NewPipeline(Pipeline):
        def __init__ (self, **kwargs):
            super().__init__(**kwargs)
            self.tr1 = Component(FunctionTransformer (lambda x: x+1))
            self.tr2 = Component(FunctionTransformer (lambda x: x*2))
    pipeline = NewPipeline()
    result = pipeline.transform (3)
    print (result)
    assert result == 8

# Comes from compose.ipynb, cell
#@pytest.mark.reference_fails
def test_pipeline_set_comp ():
    #2. by using `set_components`
    class NewPipeline(Pipeline):
        def __init__ (self, **kwargs):
            super().__init__(**kwargs)
            tr1 = Component(FunctionTransformer (lambda x: x+1))
            tr2 = Component(FunctionTransformer (lambda x: x*2))
            self.set_components (tr1, tr2)

            # the following transform is not added to the pipeline component list:
            self.tr3 = Component(FunctionTransformer (lambda x: x+1))

            # The reason is that once set_components is called, the component list
            # is frozen and inmutable setting new components by attribute doesn't
            # result in adding them to the component list

    pipeline = NewPipeline()
    result = pipeline.transform (3)

    assert result == 8
    assert len(pipeline.components) == 2
    print (result, len(pipeline.components))

# Comes from compose.ipynb, cell
#@pytest.mark.reference_fails
def test_athena_pipeline_training ():
#3. after calling `set_components()`, we can add new components with `add_component()`
    class NewPipeline(Pipeline):
        def __init__ (self, **kwargs):
            super().__init__(**kwargs)
            tr1 = Component(FunctionTransformer (lambda x: x+1))
            tr2 = Component(FunctionTransformer (lambda x: x*2))
            self.set_components (tr1, tr2)

            tr3 = Component(FunctionTransformer (lambda x: x+2))
            self.add_component(tr3)

    pipeline = NewPipeline()
    result = pipeline.transform (3)

    assert result == 10
    assert len(pipeline.components) == 3
    print (result, len(pipeline.components))

# Comes from compose.ipynb, cell
#@pytest.mark.reference_fails
def test_pipeline_load_estimator ():
    # test `load_estimator` method

    # Transform1: custom Transform
    class Transform1 (PickleSaverComponent):

        def __init__ (self, **kwargs):
            super().__init__ (**kwargs)
            self.estimator= Bunch(inv_c = 1)

        def _fit (self, X, y=None):
            self.estimator.inv_c = X.ravel()[0]

        def _apply (self, x):
            return x / self.estimator.inv_c

    class NewPipeline (Pipeline):

        def __init__ (self, **kwargs):
            super().__init__ (**kwargs)

            # custom transform
            self.tr1 = Transform1(**kwargs)

            # slklearn transform
            self.tr2 = PickleSaverComponent(StandardScaler(), **kwargs)

        def _fit (self, X, y=None):
            self.tr1.fit (X)
            self.tr2.fit (X)

    # remove any previously stored
    path_results = 'pipeline_loading_saving'
    remove_previous_results (path_results=path_results)

    pipeline = NewPipeline(path_results=path_results, save_test_result=False)
    pipeline.fit (np.array([3,4,5]).reshape(-1,1))
    result1 = pipeline.transform (np.array([300,400,500]).reshape(-1,1))
    print (pipeline.tr2.estimator.mean_)

    del pipeline
    pipeline = NewPipeline(path_results=path_results, save_test_result=False)
    pipeline.load_estimator ()
    print (pipeline.tr2.estimator.mean_)
    result2 = pipeline.transform (np.array([300,400,500]).reshape(-1,1))

    np.testing.assert_array_equal (result1, result2)

    # remove stored files resulting from running the current test
    remove_previous_results (path_results=path_results)

# Comes from compose.ipynb, cell
#@pytest.mark.reference_fails
def test_make_pipeline ():
    tr1 = Component(FunctionTransformer (lambda x: x+1))
    tr2 = Component(FunctionTransformer (lambda x: x*2))
    pipeline = make_pipeline (tr1, tr2)
    result = pipeline.transform (3)

    print (result)
    assert result == 8

# Comes from compose.ipynb, cell
#@pytest.mark.reference_fails
def test_column_selector ():
    df = pd.DataFrame ({'x1': list(range(5)),
                    'x2': list(range(5,10)),
                    'x3': list(range(15,20)),
                    'x4': list(range(25,30))
                   })
    dfr = ColumnSelector(columns=['x2','x4']).transform(df)
    assert (dfr==df[['x2','x4']]).all().all()

# Comes from compose.ipynb, cell
def column_transformer_data ():
    df = pd.DataFrame ({'cont1': list(range(5)),
                        'cont2': list(range(5,10)),
                        'cont3': list(range(15,20)),
                        'cont4': list(range(25,30)),
                        'cat_1': list([1,2,3,2,1]),
                        'cat_2': list([0,1,1,0,0])
                        })

    tr1 = Component(FunctionTransformer (lambda x: x+1), name='tr1')

    return df, tr1

#@pytest.mark.reference_fails
def test_make_column_transformer (column_transformer_data):

    df, tr1 = column_transformer_data

    tr1 = Component(FunctionTransformer (lambda x: x+1), name='tr1')
    tr2 = PandasComponent(FunctionTransformer (lambda x: x*2), transformed_columns=['cont2_bis','cat_1'], name='tr2')

    column_transformer = make_column_transformer (
        (tr1, ['cont2', 'cont4']),
        (tr2, ['cont2', 'cat_1'])
    )
    dfr = column_transformer.transform(df)

    # display and test
    display(dfr)
    assert (dfr[['cont2','cont4']] == tr1(df[['cont2','cont4']])).all().all()
    assert (dfr[['cont2_bis','cat_1']] == tr2(df[['cont2','cat_1']])).all().all()
    assert (dfr.columns == ['cont2','cont4', 'cont2_bis','cat_1']).all()
    assert (column_transformer.name, column_transformer.class_name) == ('__base_column_transformer', '_BaseColumnTransformer')

    # set name of column transformer
    column_transformer = make_column_transformer (
        (tr1, ['cont2', 'cont4']),
        (tr2, ['cont2', 'cat_1']),
        name='test_transformer',
        class_name='TestTransformer'
    )
    assert (column_transformer.name, column_transformer.class_name) == ('test_transformer', 'TestTransformer')

    # set name of column transformer and parameters that are specific
    # for the column_transformer: path_results
    column_transformer = make_column_transformer (
        (tr1, ['cont2', 'cont4']),
        (tr2, ['cont2', 'cat_1']),
        name='test_transformer',
        class_name='TestTransformer',
        TestTransformer=dict(path_results='mine'),
        path_results='other'
    )
    assert column_transformer.path_results.name=='mine'
    assert column_transformer.components[0].path_results.name=='other'

# Comes from compose.ipynb, cell
#@pytest.mark.reference_fails
def test_make_column_transformer_passthrough (column_transformer_data):
    df, tr1 = column_transformer_data

    column_transformer = make_column_transformer (
        (tr1, ['cont1', 'cont4']),
        ('passthrough', ['cont2', 'cat_1'])
    )
    dfr = column_transformer.transform(df)

    # display and test
    display(dfr)
    assert (dfr[['cont1','cont4']] == tr1(df[['cont1','cont4']])).all().all()
    assert (dfr[['cont2','cat_1']] == df[['cont2','cat_1']]).all().all()
    assert (dfr.columns == ['cont1','cont4', 'cont2','cat_1']).all()

# Comes from compose.ipynb, cell
#@pytest.mark.reference_fails
def test_make_column_transformer_remainder (column_transformer_data):

    df, tr1 = column_transformer_data

    # remainder is new transformation
    tr3 = Component(FunctionTransformer (lambda x: x+100), name='tr3')
    column_transformer = make_column_transformer (
        (tr1, ['cont1', 'cont4']),
        ('passthrough', ['cont2', 'cat_1']),
        remainder=tr3
    )
    dfr = column_transformer.transform(df)

    # display and test
    display('with tr3', dfr)
    assert (dfr[['cont1','cont4']] == tr1(df[['cont1','cont4']])).all().all()
    assert (dfr[['cont2','cat_1']] == df[['cont2','cat_1']]).all().all()
    assert (dfr[['cont3','cat_2']] == tr3(df[['cont3','cat_2']])).all().all()
    assert (dfr.columns == ['cont1','cont4', 'cont2','cat_1','cont3','cat_2']).all()

    # remainder is passthrough
    del tr1.nick_name
    del tr3.nick_name
    column_transformer = make_column_transformer (
        (tr1, ['cont1', 'cont4']),
        (tr3, ['cont2', 'cat_1']),
        remainder='passthrough'
    )
    dfr = column_transformer.transform(df)

    display('with passthrough', dfr)
    assert (dfr[['cont1','cont4']] == tr1(df[['cont1','cont4']])).all().all()
    assert (dfr[['cont2','cat_1']] == tr3(df[['cont2','cat_1']])).all().all()
    assert (dfr[['cont3','cat_2']] == df[['cont3','cat_2']]).all().all()
    assert (dfr.columns == ['cont1','cont4', 'cont2','cat_1','cont3','cat_2']).all()

    # remainder is tr3, and one of the transforms is drop
    del tr1.nick_name
    del tr3.nick_name
    column_transformer = make_column_transformer (
        (tr1, ['cont1', 'cont4']),
        ('drop', ['cont2', 'cat_1']),
        remainder=tr3
    )
    dfr = column_transformer.transform(df)

    display('with drop one of the transforms - cont2, cat_1', dfr)
    assert (dfr[['cont1','cont4']] == tr1(df[['cont1','cont4']])).all().all()
    assert (dfr[['cont3','cat_2']] == tr3(df[['cont3','cat_2']])).all().all()
    assert (dfr.columns == ['cont1','cont4', 'cont3','cat_2']).all()

    # check gather_descendants
    column_transformer.gather_descendants()
    assert sorted(column_transformer.full_obj.keys())==['column_selector', 'concat', 'tr1', 'tr1_cc', 'tr3', 'tr3_rem']

# Comes from compose.ipynb, cell
#@pytest.mark.reference_fails
def test_make_column_transformer_descendants (column_transformer_data):

    df, tr1 = column_transformer_data

    tr3 = Component(FunctionTransformer (lambda x: x+100), name='tr3')

    column_transformer = make_column_transformer (
        (tr1, ['cont1', 'cont4']),
        ('drop', ['cont2', 'cat_1']),
        remainder=tr3
    )

    # check gather_descendants
    column_transformer.gather_descendants()
    assert sorted(column_transformer.full_obj.keys())==['column_selector', 'concat', 'tr1', 'tr1_cc', 'tr3', 'tr3_rem']

# Comes from compose.ipynb, cell
#@pytest.mark.reference_fails
def test_make_column_transformer_fit_transform (column_transformer_data):

    df, tr1 = column_transformer_data

    class SumTimes100 (Component):
        def _fit (self, X, y=None):
            self.sum = X.sum(axis=0)
        def _apply (self, X):

            dfr = pd.DataFrame ({'c1_times100': self.sum.values[0]*100 + X.iloc[:,0].values,
                                 'c2_times100': self.sum.values[1]*100 + X.iloc[:,1].values,
                                 'c2_times1000': self.sum.values[1]*1000 + X.iloc[:,1].values})
            return dfr

    tr1 = SumTimes100 ()
    tr2 = PandasComponent(FunctionTransformer (lambda x: x*2), name='tr2')

    column_transformer = make_column_transformer (
        (tr1, ['cont2', 'cont4']),
        (tr2, ['cont2', 'cat_1'])
    )
    dfr = column_transformer.fit_transform(df)

    # display & test
    display(dfr)
    assert (dfr.columns == ['c1_times100','c2_times100', 'c2_times1000','cont2', 'cat_1']).all()
    assert (dfr['c1_times100'] == sum(df.cont2)*100+df.cont2).all()
    assert (dfr['c2_times100'] == sum(df.cont4)*100+df.cont4).all()
    assert (dfr['c2_times1000'] == sum(df.cont4)*1000+df.cont4).all()

# Comes from compose.ipynb, cell
class Transform1 (Component):
    def __init__ (self, **kwargs):
        super().__init__ (**kwargs)
        self.estimator= Bunch(sum = 1)

    def _fit (self, X, y=None):
        self.estimator.sum = X.sum(axis=0)

    def _apply (self, x):
        return x*1000 + self.estimator.sum

class Transform2 (Component):
    def __init__ (self, **kwargs):
        super().__init__ (**kwargs)
        self.estimator= Bunch(maxim = 1)

    def _fit (self, X, y=None, validation_data=None, test_data=None):
        self.estimator.maxim = X.max(axis=0)

        print (f'validation_data: {validation_data}')
        print (f'test_data: {test_data}')

        self.data = dict (validation=validation_data,
                          test=test_data)

    def _apply (self, x):
        return x*100 + self.estimator.maxim

def multi_split_data ():
    data = dict(training = np.array([1,2,3]).reshape(-1,1),
            validation = np.array([10,20,30]).reshape(-1,1),
            test = np.array([100,200,300]).reshape(-1,1)
            )

    multi_transform1 = MultiSplitComponent (component = Transform1())

    tr2 = Transform2()
    multi_transform2 = MultiSplitComponent (component=tr2,
                                            fit_additional = ['validation', 'test'])

    return data, multi_transform1, multi_transform2, tr2

#@pytest.mark.reference_fails
def test_multi_split_transform (multi_split_data):
    # example 1: apply transform on multiple splits
    data, multi_transform1, multi_transform2, tr2 = multi_split_data

    result = multi_transform1.fit_transform (data)

    assert type(result) is dict
    assert result.keys() == data.keys()
    for split in result.keys():
        assert (result[split]==sum(data['training'].ravel())+data[split]*1000).all()

    # check that automatic name given is based on component
    assert multi_transform1.name=='transform1_multi_split'
    assert multi_transform1.class_name=='Transform1MultiSplit'

    # check that we can assign a different name
    multi_transform1 = MultiSplitComponent (component = Transform1(), name='different', class_name='Yes')
    assert multi_transform1.name=='different'
    assert multi_transform1.class_name=='Yes'
    # check that this new name is given only to MultiSplitComponent,
    # not to the component that it's wrapping
    assert multi_transform1.component.name=='transform1'
    assert multi_transform1.component.class_name=='Transform1'

# Comes from compose.ipynb, cell
#@pytest.mark.reference_fails
def test_multi_split_fit (multi_split_data):
    # example 2: fit method gets training, validation and test
    data, multi_transform1, multi_transform2, tr2 = multi_split_data
    # we apply the transform to only test


    # we apply the transform to only test data
    result = multi_transform2.fit_transform (data, apply_to='test')

    assert type(result) is dict
    assert list(result.keys()) == ['test']
    for split in result.keys():
        assert (result[split]==max(data['training'].ravel())+data[split]*100).all()

    for split in ['validation', 'test']:
        assert (tr2.data[split] == data[split]).all()

# Comes from compose.ipynb, cell
#@pytest.mark.reference_fails
def test_multi_split_chain (multi_split_data):
    data, multi_transform1, multi_transform2, tr2 = multi_split_data

    # test that we can chain transformations

    result = multi_transform1.fit_transform (data)
    result = multi_transform2.fit_transform (result, apply_to='test')

    import pytest

    #check that we have no error if split does not exist
    result = multi_transform1.fit_transform (data, apply_to=['training', 'validation'])
    result = multi_transform2.fit_transform (result, apply_to=['test'])
    assert len(result)==0

    #check that we have an error if we set the flag `raise_error_if_split_doesnot_exist=True`
    multi_transform2.raise_error_if_split_doesnot_exist = True
    result = multi_transform1.fit_transform (data, apply_to=['training', 'validation'])
    with pytest.raises (RuntimeError):
        result = multi_transform2.fit_transform (result, apply_to=['test'])

# Comes from compose.ipynb, cell
#@pytest.mark.reference_fails
def test_multi_split_io (multi_split_data):

    data, multi_transform1, multi_transform2, tr2 = multi_split_data

    # check loading / saving
    from block_types.utils.utils import remove_previous_results
    from block_types.core.utils import PickleIO

    path_results = 'results_multi_split'

    remove_previous_results (path_results=path_results)

    tr = PickleSaverComponent (FunctionTransformer (lambda x: x*2),
                    name='times2',
                    path_results=path_results)

    multi_transform = MultiSplitComponent (component=tr,
                                           apply_to = ['validation', 'test'],
                                           path_results = path_results,
                                           data_io=PickleIO (path_results = path_results))

    result = multi_transform (data)

    multi_transform2 = MultiSplitComponent (data_io=PickleIO (path_results = path_results), name='times2_multi_split')

    result2 = multi_transform2.data_io.load_result ()

    for k in result.keys():
        assert (result[k] == result2[k]).all()

    assert result.keys()==result2.keys()

    assert sorted(os.listdir(path_results))==['test', 'validation', 'whole']

    assert (tr.data_io.load_result(split='test') == result['test']).all()

    assert (tr.data_io.load_result(split='validation') == result['validation']).all()

    assert os.listdir(f'{path_results}/validation')==['times2_result.pk']

    assert os.listdir(f'{path_results}/test')==['times2_result.pk']

    assert os.listdir(f'{path_results}/whole')==['times2_multi_split_result.pk']

    remove_previous_results (path_results=path_results)

# Comes from compose.ipynb, cell
#@pytest.mark.reference_fails
def test_multi_split_non_dict ():
    # check loading / saving
    tr = Component (FunctionTransformer (lambda x: x*2))

    multi_transform = MultiSplitComponent (tr, apply_to = ['test'])

    data = np.array([100,200,300]).reshape(-1,1)
    result = multi_transform (data)

    assert type(result)==np.ndarray
    assert (result==data*2).all()

# Comes from compose.ipynb, cell
#@pytest.mark.reference_fails
def test_multi_split_non_dict_bis ():
    tr = Component (FunctionTransformer (lambda x: x*2))

    multi_transform = MultiSplitComponent (tr, apply_to = ['test'])

    # output applied to single split, converted to non-dictionary
    data = dict(training = np.array([1,2,3]).reshape(-1,1),
                validation = np.array([10,20,30]).reshape(-1,1),
                test = np.array([100,200,300]).reshape(-1,1))
    result = multi_transform (data, output_not_dict=True)

    assert type(result)==np.ndarray
    assert (result==data['test']*2).all()
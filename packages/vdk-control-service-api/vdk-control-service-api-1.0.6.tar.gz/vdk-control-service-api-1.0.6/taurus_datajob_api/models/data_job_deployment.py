# coding: utf-8

"""
    Versatile Data Kit Control Service API

    The Data Jobs API of Versatile Data Kit Control Service. Data Jobs allows Data Engineers to implement automated pull ingestion (E in ELT) and batch data transformation into a database (T in ELT). See also https://github.com/vmware/versatile-data-kit/wiki/Introduction  The API has resource-oriented URLs, JSON-encoded responses, and uses standard HTTP response codes, authentication, and verbs. The API enables creating, deploying, managing and executing Data Jobs in the runtime environment.<br> <br> ![](https://github.com/vmware/versatile-data-kit/wiki/vdk-data-job-lifecycle-state-diagram.png) <br> The API reflects the usual Data Job Development lifecycle:<br> <li> Create a new data job (webhook to further configure the job, e.g authorize its creation, setup permissions, etc). <li> Download keytab. Develop and run the data job locally. <li> Deploy the data job in cloud runtime environment to run on a scheduled basis. <br><br> If Authentication is enabled, pass OAuth2 access token in HTTP header 'Authorization: Bearer [access-token-here]' (https://datatracker.ietf.org/doc/html/rfc6750). <br  The API promotes some best practices (inspired by https://12factor.net): <li> Explicitly declare and isolate dependencies. <li> Strict separation of configurations from code. Configurations vary substantially across deploys, code does not. <li> Separation between the build, release/deploy, and run stages. <li> Data Jobs are stateless and share-nothing processes. Any data that needs to be persisted must be stored in a stateful backing service (e.g IProperties). <li> Implementation is assumed to be atomic and idempotent - should be OK for a job to fail somewhere in the middle; subsequent restart should not cause data corruption. <li> Keep development, staging, and production as similar as possible. <br><br> <b>API Evolution</b><br> In the following sections, there are some terms that have a special meaning in the context of the APIs. <br><br> <li> <i>Stable</i> - The implementation of the API has been battle-tested (has been in production for some time).                      The API is a subject to semantic versioning model and will follow deprecation policy. <li> <i>Experimental</i> - May disappear without notice and is not a subject to semantic versioning.                            Implementation of the API is not considered stable nor well tested.                            Generally this is given to clients to experiment within testing environment. Must not be used in production. <li> <i>Deprecated</i> - API is expected to be removed within next one or two major version upgrade.                          The deprecation notice/comment will say when the API will be removed and what alternatives should be used instead.   # noqa: E501

    The version of the OpenAPI document: 1.0
    Generated by: https://openapi-generator.tech
"""


import pprint
import re  # noqa: F401

import six

from taurus_datajob_api.configuration import Configuration


class DataJobDeployment(object):
    """NOTE: This class is auto generated by OpenAPI Generator.
    Ref: https://openapi-generator.tech

    Do not edit the class manually.
    """

    """
    Attributes:
      openapi_types (dict): The key is attribute name
                            and the value is attribute type.
      attribute_map (dict): The key is attribute name
                            and the value is json key in definition.
    """
    openapi_types = {
        'vdk_version': 'str',
        'job_version': 'str',
        'mode': 'DataJobMode',
        'id': 'str',
        'enabled': 'bool',
        'deployed_by': 'str',
        'deployed_date': 'datetime',
        'schedule': 'DataJobSchedule',
        'resources': 'DataJobResources'
    }

    attribute_map = {
        'vdk_version': 'vdk_version',
        'job_version': 'job_version',
        'mode': 'mode',
        'id': 'id',
        'enabled': 'enabled',
        'deployed_by': 'deployed_by',
        'deployed_date': 'deployed_date',
        'schedule': 'schedule',
        'resources': 'resources'
    }

    def __init__(self, vdk_version=None, job_version=None, mode=None, id=None, enabled=None, deployed_by=None, deployed_date=None, schedule=None, resources=None, local_vars_configuration=None):  # noqa: E501
        """DataJobDeployment - a model defined in OpenAPI"""  # noqa: E501
        if local_vars_configuration is None:
            local_vars_configuration = Configuration()
        self.local_vars_configuration = local_vars_configuration

        self._vdk_version = None
        self._job_version = None
        self._mode = None
        self._id = None
        self._enabled = None
        self._deployed_by = None
        self._deployed_date = None
        self._schedule = None
        self._resources = None
        self.discriminator = None

        if vdk_version is not None:
            self.vdk_version = vdk_version
        if job_version is not None:
            self.job_version = job_version
        if mode is not None:
            self.mode = mode
        if id is not None:
            self.id = id
        if enabled is not None:
            self.enabled = enabled
        if deployed_by is not None:
            self.deployed_by = deployed_by
        if deployed_date is not None:
            self.deployed_date = deployed_date
        if schedule is not None:
            self.schedule = schedule
        if resources is not None:
            self.resources = resources

    @property
    def vdk_version(self):
        """Gets the vdk_version of this DataJobDeployment.  # noqa: E501

        A specific VDK version to use  # noqa: E501

        :return: The vdk_version of this DataJobDeployment.  # noqa: E501
        :rtype: str
        """
        return self._vdk_version

    @vdk_version.setter
    def vdk_version(self, vdk_version):
        """Sets the vdk_version of this DataJobDeployment.

        A specific VDK version to use  # noqa: E501

        :param vdk_version: The vdk_version of this DataJobDeployment.  # noqa: E501
        :type: str
        """

        self._vdk_version = vdk_version

    @property
    def job_version(self):
        """Gets the job_version of this DataJobDeployment.  # noqa: E501

        Job version (can be Git commit)  # noqa: E501

        :return: The job_version of this DataJobDeployment.  # noqa: E501
        :rtype: str
        """
        return self._job_version

    @job_version.setter
    def job_version(self, job_version):
        """Sets the job_version of this DataJobDeployment.

        Job version (can be Git commit)  # noqa: E501

        :param job_version: The job_version of this DataJobDeployment.  # noqa: E501
        :type: str
        """

        self._job_version = job_version

    @property
    def mode(self):
        """Gets the mode of this DataJobDeployment.  # noqa: E501


        :return: The mode of this DataJobDeployment.  # noqa: E501
        :rtype: DataJobMode
        """
        return self._mode

    @mode.setter
    def mode(self, mode):
        """Sets the mode of this DataJobDeployment.


        :param mode: The mode of this DataJobDeployment.  # noqa: E501
        :type: DataJobMode
        """

        self._mode = mode

    @property
    def id(self):
        """Gets the id of this DataJobDeployment.  # noqa: E501

        String that identifies a single deployment of a Data Job. Currently only one single deployment per Data Job is possible.<br> In the future:<br> It's recommended to use following ids - development, testing, production. However users are free to come up with their own. For example, this enables the creation of 3 different deployments, using the same Data Job code:<br> `development  deployment  --deployment-id development`<br> `testing deployment  --deployment-id testing`<br> `production deployment  --deployment-id prod`   # noqa: E501

        :return: The id of this DataJobDeployment.  # noqa: E501
        :rtype: str
        """
        return self._id

    @id.setter
    def id(self, id):
        """Sets the id of this DataJobDeployment.

        String that identifies a single deployment of a Data Job. Currently only one single deployment per Data Job is possible.<br> In the future:<br> It's recommended to use following ids - development, testing, production. However users are free to come up with their own. For example, this enables the creation of 3 different deployments, using the same Data Job code:<br> `development  deployment  --deployment-id development`<br> `testing deployment  --deployment-id testing`<br> `production deployment  --deployment-id prod`   # noqa: E501

        :param id: The id of this DataJobDeployment.  # noqa: E501
        :type: str
        """

        self._id = id

    @property
    def enabled(self):
        """Gets the enabled of this DataJobDeployment.  # noqa: E501

        Enable/disable flag  # noqa: E501

        :return: The enabled of this DataJobDeployment.  # noqa: E501
        :rtype: bool
        """
        return self._enabled

    @enabled.setter
    def enabled(self, enabled):
        """Sets the enabled of this DataJobDeployment.

        Enable/disable flag  # noqa: E501

        :param enabled: The enabled of this DataJobDeployment.  # noqa: E501
        :type: bool
        """

        self._enabled = enabled

    @property
    def deployed_by(self):
        """Gets the deployed_by of this DataJobDeployment.  # noqa: E501

        User or service that deployed the Data Job  # noqa: E501

        :return: The deployed_by of this DataJobDeployment.  # noqa: E501
        :rtype: str
        """
        return self._deployed_by

    @deployed_by.setter
    def deployed_by(self, deployed_by):
        """Sets the deployed_by of this DataJobDeployment.

        User or service that deployed the Data Job  # noqa: E501

        :param deployed_by: The deployed_by of this DataJobDeployment.  # noqa: E501
        :type: str
        """

        self._deployed_by = deployed_by

    @property
    def deployed_date(self):
        """Gets the deployed_date of this DataJobDeployment.  # noqa: E501

        The Data Job deployment date  # noqa: E501

        :return: The deployed_date of this DataJobDeployment.  # noqa: E501
        :rtype: datetime
        """
        return self._deployed_date

    @deployed_date.setter
    def deployed_date(self, deployed_date):
        """Sets the deployed_date of this DataJobDeployment.

        The Data Job deployment date  # noqa: E501

        :param deployed_date: The deployed_date of this DataJobDeployment.  # noqa: E501
        :type: datetime
        """

        self._deployed_date = deployed_date

    @property
    def schedule(self):
        """Gets the schedule of this DataJobDeployment.  # noqa: E501


        :return: The schedule of this DataJobDeployment.  # noqa: E501
        :rtype: DataJobSchedule
        """
        return self._schedule

    @schedule.setter
    def schedule(self, schedule):
        """Sets the schedule of this DataJobDeployment.


        :param schedule: The schedule of this DataJobDeployment.  # noqa: E501
        :type: DataJobSchedule
        """

        self._schedule = schedule

    @property
    def resources(self):
        """Gets the resources of this DataJobDeployment.  # noqa: E501


        :return: The resources of this DataJobDeployment.  # noqa: E501
        :rtype: DataJobResources
        """
        return self._resources

    @resources.setter
    def resources(self, resources):
        """Sets the resources of this DataJobDeployment.


        :param resources: The resources of this DataJobDeployment.  # noqa: E501
        :type: DataJobResources
        """

        self._resources = resources

    def to_dict(self):
        """Returns the model properties as a dict"""
        result = {}

        for attr, _ in six.iteritems(self.openapi_types):
            value = getattr(self, attr)
            if isinstance(value, list):
                result[attr] = list(map(
                    lambda x: x.to_dict() if hasattr(x, "to_dict") else x,
                    value
                ))
            elif hasattr(value, "to_dict"):
                result[attr] = value.to_dict()
            elif isinstance(value, dict):
                result[attr] = dict(map(
                    lambda item: (item[0], item[1].to_dict())
                    if hasattr(item[1], "to_dict") else item,
                    value.items()
                ))
            else:
                result[attr] = value

        return result

    def to_str(self):
        """Returns the string representation of the model"""
        return pprint.pformat(self.to_dict())

    def __repr__(self):
        """For `print` and `pprint`"""
        return self.to_str()

    def __eq__(self, other):
        """Returns true if both objects are equal"""
        if not isinstance(other, DataJobDeployment):
            return False

        return self.to_dict() == other.to_dict()

    def __ne__(self, other):
        """Returns true if both objects are not equal"""
        if not isinstance(other, DataJobDeployment):
            return True

        return self.to_dict() != other.to_dict()
